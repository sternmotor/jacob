https://www.linux-magazin.de/ausgaben/2013/07/postgresql-tuning/2/



Storage:

* I/O ops/sec sind weit wichtiger als throughput
    * mehr Platten
    * SSD
    * eher Raid 10, Raid 50 als Raid5
* scheduler: elevator=deadline


CPU
* viel Takt, wichtiger als viele Kerne, 1 Abfrage=1 Core


FS:
* noatime, nodiratime


MEM:

Postgres Log ansehen
* "FATAL:  could not create shared memory segment: No space left on device"
    * shmall vergrößern
* "FATAL:  could not create shared memory segment: Invalid argument"
    * shmmax vergrößern



Shared Memory Segment (shared_buffers):
* 25% des RAM, bei 16GB RAM 4GB
    * kernel.shmmax=$(( 4*1024*1024*1024*1024 )) 
    * kernel.shmmall=$(( 4*1024*1024*1024*1024/4096 ))   # size inpages, see `ipcs-lm` (max number of segments )
    * `postgres.conf`: shared_buffers = 4GB

 
effective_cache_size: = 50...75% RAM
# help query planner deciding when to use indexes for query
* 16GB: effective_cache_size = 10GB 


* WAL bin log files: 16MB * 16 segements = 256 MB 
    * lesser number of checkpoints > faster writes
    * more binlogs to read > slower recovery

    * checkpoint_segments = 16

PostgreSQL bemüht sich darum, die für einen Checkpoint nötigen Schreiboperationen möglichst schon vor dem eigentlichen Checkpoint zu erledigen, damit der schneller vonstatten gehen kann. Der Parameter »checkpoint_completion_target« definiert dabei die zeitliche Distanz bis zum nächsten Checkpoint. Bei einem Standardwert von »0.5« versucht PostgreSQL, alle Operationen in der ersten Halbzeit vor dem nächsten Checkpoint zu erledigen. Wer »checkpoint_segments« auf einen sinnvollen Wert erhöht hat (größer als 10), sollte diesen Wert auf »0.9« stellen, um so die Schreiboperationen gleichmäßiger zu verteilen.

    * checkpoint_completion_target = 0.9


Mem used for sort operations per query (=db connection)
    3 sort operations * 200 connections * 8MB (standard) = 5GB
work_mem: 


synchronous_commit = off : bringt 2.5 x performance beim schreiben der WAL Dateiene da auf das Commit verzichtet wird.nach einem ServerCrash sind aber die letzten Daten hinüber. Das wäre was für einen Cluster. Bedenke: WAL


# log_temp_files = 0: log expensive usage of temp files instead of cache mem
log_temp_files = 0

log_min_duration_statement: 100 = log all queries taking > 100 milliseconds



https://raw.githubusercontent.com/jfcoz/postgresqltuner/master/postgresqltuner.pl

[BAD]     Some plan features are disabled: enable_partitionwise_aggregate,enable_partitionwise_join


http://engineering.pivotal.io/post/virtual_memory_settings_in_linux_-_the_problem_with_overcommit/

Here is the formula for not using Swap, but using all RAM:
    Overcommit Ratio = 100 * ((RAM - Swap Space) / RAM)

    16GB RAM, 2GB SWAP: 
    echo 87 > /proc/sys/vm/overcommit_ratio
    echo 2 > /proc/sys/vm/overcommit_memory





[HIGH] set vm.overcommit_memory=2 in /etc/sysctl.conf and invoke  sysctl -p /etc/sysctl.conf  to enforce it.  This will disable memory overcommitment and avoid having a PostgreSQL process killed by the OOM killer






* Wie groß wird die Datenbank? (Eine kleine fürs Web oder ein DataWarehouse?)

* Wie schreiblastig arbeitet die Datenbank? (Wie ist das Verhältnis zwischen »SELECT« und »INSERT« oder »UPDATE« ?)
* Muss der Admin die Daten aufwändig analysieren? (Sind komplexe SQL-Queries nötig?)








